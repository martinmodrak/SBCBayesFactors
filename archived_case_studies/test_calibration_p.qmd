---
title: "test_calibration"
format: html
---

```{r setup}
library(ggplot2)
library(dplyr)
theme_set(theme_minimal())
devtools::load_all()
```

```{r cluster}
setup_cluster()
```


```{r}
test_single <- function(probs_generator, bias = 0, sd = 0, func = calibration_p_saddle, ...) {
  dotlist <- list(...)
  ps <- replicate(100, {
    probs <- do.call(probs_generator, dotlist)
    if(bias != 0 || sd != 0) {
      probs_to_sim <- plogis(
        qlogis(probs) + bias + rnorm(length(probs), mean = 0, sd = sd)
        )
    } else {
      probs_to_sim <- probs
    }
    ys <- rbinom(length(probs), size = 1, prob = probs_to_sim)
    func(probs, ys)
  })
  
  return(ps)
}

func <-  miscalibration_resampling_p
ps <- test_single(runif, func = func, n = 100)
hist(ps)

ps <- test_single(\(n) rbinom(n, size = 1, prob = 0.5), func = func, n = 100)
hist(ps)


ps <- test_single(runif, func = func, n = 10000, bias = 0.5)
hist(ps)

dd <- rbeta(50, 2,1)
hoeffding_p(dd)


probs <- plogis(qlogis(runif(1000)) + 0.5)
hoeffding_p(probs)

ps <- test_single(\(n) rbinom(n, size = 1, prob = 0.4) * 0.3 + 0.2, func = func, n = 1000)
hist(ps)

```


# DAP tests

```{r}
test_DAP_single <- function(probs_generator, bias = 0, sd = 0, func = calibration_p_saddle, n_rep = 100, ...) {
  dotlist <- list(...)
  ps <- replicate(n_rep, {
    probs <- do.call(probs_generator, dotlist)
    if(bias != 0 || sd != 0) {
      probs <- plogis(
        qlogis(probs) + bias + rnorm(length(probs), mean = 0, sd = sd)
        )
    } 
    func(probs)
  })
  
  return(ps)
}


func <- bentkus_p

t_test_p <- function(probs) {
  t <- t.test(probs, mu = 0.5)
  return(t$p.value)
}

ps <- test_DAP_single(rbeta, shape1 = 2, shape2 = 1, n = 20, func = bentkus_p)
#hist(ps)
mean(ps < 0.05)
ps <- test_DAP_single(rbeta, shape1 = 2, shape2 = 1, n = 20, func = hoeffding_p)
#hist(ps)
mean(ps < 0.05)
ps <- test_DAP_single(rbeta, shape1 = 2, shape2 = 1, n = 20, func = t_test_p)
#hist(ps)
mean(ps < 0.05)

ps <- test_DAP_single(runif, n = 10, func = ml_dap_p, n_rep = 1000)
mean(ps < 0.05)
mean(ps < 0.1)
hist(ps)

ps <- test_DAP_single(runif, n = 30, func = ml_dap_p, n_rep = 1000)
mean(ps < 0.05)
mean(ps < 0.1)
hist(ps)

ps <- test_DAP_single(runif, n = 100, func = ml_dap_p)
hist(ps)

ps <- test_DAP_single(runif, n = 1000, func = ml_dap_p)
hist(ps)


ps <- test_DAP_single(\() rbinom(n = 100000, size = 1, prob = 0.5) * 0.5 + 0.25, func = t_test_p)
hist(ps)

ps <- test_DAP_single(\() rbinom(n = 100, size = 1, prob = 0.5) * 0.5 + 0.25, func = ml_dap_p)
hist(ps)


```


```{r}

gaffke_p(c(0.9,0.9, 1))

```

```{r}
aug_boot_p <- function(probs, mu = 1, B = 10000) {
  B_lwr <- matrix(sample(c(0, probs), size = B * (length(probs) + 1), replace = TRUE), nrow = B)
  #lwr <- quantile(rowMeans(B_lwr), prob = 0.025)
  # B_upr <- matrix(sample(c(1, probs), size = B * (length(probs) + 1), replace = TRUE), nrow = B)
  # upr <- quantile(rowMeans(B_upr), prob = 0.975)
  #as.numeric(c(lwr, upr))
  mean(B_lwr <= mu)
}
```


```{r}
ml_dap_p <- function(probs, mu = 0.5, B = 2000, alternative = c("two.sided", "less", "greater")) {
  alternative <- match.arg(alternative)
  s_probs <- sum(probs)
  n <- length(probs)
  m_probs <- s_probs/n
  if(m_probs == mu) {
    return(1)
  } else if(m_probs > mu) {
    if(alternative == "greater") {
      return(1)
    } else {
      e_probs <- c(probs, 0)
      a <- 1 - mu / m_probs
      p_probs <- c(rep(mu / s_probs, n), a)
      bs_matrix <- matrix(nrow = B, ncol = n, sample(e_probs, prob = p_probs, size = B * n, replace = TRUE))
      bs <- rowMeans(bs_matrix)
      p_one_side <- mean(bs >= m_probs)
      if(alternative == "two.sided") {
        return(min(1, p_one_side * 2))
      } else {
        return(p_one_side)
      }
    }
  } else {
    if(alternative == "less") {
      return(1)
    } else {
      alt_flip <- c("two.sided" = "two.sided", "greater" = "less")
      return(ml_dap_p(probs = 1 - probs, mu = 1 - mu, B = B, alternative = alt_flip[alternative]))
    }
  }
}
```


```{r}
ml_dap_p_one_sided <- function(x, mu = 1, B = 2000) {
  # scale to mu = 1
  x <- x / mu
  
  s_x <- sum(x)
  n <- length(x)
  m_x <- s_x/n
  
  if(m_x <= 1){
    return(1)
  }
  A <- 1 - 1/m_x
  e_x <- c(x, 0)
  p_x <- c(rep(1 / s_x, n), A)
  bs_matrix <- matrix(nrow = B, ncol = n, sample(e_x, prob = p_x, size = B * n, replace = TRUE))
  bs <- rowMeans(bs_matrix)
  p_one_side <- mean(bs >= m_x)
  return(p_one_side)
}
```


Counterexample?

```{r}
vt_ <- 8
vs_ <- 0.1
worst_n_ <- 2
scale_ <- TRUE

# vt_ <- 100
# vs_ <- 0.01
# worst_n_ <- 100
# scale_ <- FALSE


worst_case <- function(worst_n = worst_n_, vt = vt_, vs = vs_, scale = scale_) {
  if(vs < vt - sqrt(vt^2 - vt)) {
    values <- c(vs,vt)
    probs <- c(vt - 1, 1 - vs)
  } else {
    values <- c(0,vs,vt)
    probs <- c(1 - vt/(vs*(2*vt - vs)), (vt-vs)/(vs*(2*vt - vs)), 1 / (2*vt - vs) )
  }
  if(scale) {
    scale_val <- max(values)
  } else {
    scale_val <- 1
  }
  res <- sample(values / scale_val, size = worst_n, prob = probs, replace = TRUE)
  attr(res, "true_mean") <- sum(probs / sum(probs) * values) / scale_val
  res
}

dummy <- worst_case()
true_mean <- attr(dummy, "true_mean")

#ps <- test_DAP_single(worst_case, n_rep = 1000, func = \(x) ml_dap_p(x, mu = true_mean))
ps <- test_DAP_single(worst_case, n_rep = 1000, func = \(x) ml_dap_p(x, mu = true_mean, alternative = "less"))
#ps <- test_DAP_single(worst_case, n_rep = 1000, func = \(x) ml_dap_p_one_sided(x, mu = true_mean))
#ps <- test_DAP_single(worst_case, n_rep = 100, func = \(x) gaffke_p(x/vt, mu = 1/vt, B=2000))
#ps <- test_DAP_single(worst_case, n_rep = 100, func = \(x) aug_boot_p(x, mu = 1))

#hist(ps)
binom.test(sum(ps < 0.05), length(ps), p = 0.05, alternative = "greater")

#mean(worst_case(1e8) - true_mean)



```

```{r}
ssss <- 685542
set.seed(ssss)
scale <- TRUE
x1 <- worst_case()
ml_dap_p_one_sided(x1, mu = attr(x1, "true_mean"))

set.seed(ssss)
scale <- FALSE
x2 <- worst_case()
ml_dap_p_one_sided(x2, mu = attr(x2, "true_mean"))
```


```{r}
x <- c(1,0.5)
ml_dap_p_one_sided(x, B = 1e7)
3/(sum(x)^2)
```

```{r}
n <- 1000
#gen <- \() ifelse(runif(n = n) <= 0.5, 0.495, 0.505)
mu_beta <- 0.5
prec_beta <- 40
gen <- \() rbeta(n = n, shape1 = mu_beta * prec_beta, shape2 = (1 - mu_beta)*prec_beta)
ps <- test_DAP_single(gen, func = hoeffding_p)
mean(ps < 0.05)
ps <- test_DAP_single(gen, func = bentkus_p)
mean(ps < 0.05)
ps <- test_DAP_single(gen, func = ml_dap_p)
mean(ps < 0.05)
hist(ps)
# ps <- test_DAP_single(gen, func = t_test_p)
# mean(ps < 0.05)
```


```{r}
n <- 1
gen <- \()  dplyr::if_else(runif(n) < 0.5, 0.1, 0.5 + 0.5 * runif(n))
mu <- 0.5 * (0.1 + 0.75)
ps <- test_DAP_single(gen, func = \(probs) ml_dap_p(probs, mu = mu, alternative = "less"), n_rep = 10000)
mean(ps < 0.99)
hist(ps)

ml_dap_p(0.99, mu = mu, B = 100000, alternative = "less")
mean(ps < 0.5)

hist(ps)

gen2 <- \(n) dplyr::if_else(runif(n) < 0.5, 0.1, 0.5 + 0.5 * runif(n))
zz <- gen2(10000)
hist(dplyr::if_else(zz <= mu, 1, mu / zz))
```
```{r}
mu <- 0.05
gen <- \() rbinom(1, size = 1, prob = mu)
ps <- test_DAP_single(gen, func = \(probs) ml_dap_p(probs, mu = mu, alternative = "less"), n_rep = 1000)
hist(ps)
mean(ps < 0.05)
```

```{r}
df <- 1.5
gen <- \() abs(rt(100, df = df))
# https://distribution-explorer.github.io/continuous/halfstudent_t.html
mu <- 2 * sqrt(df / pi) * gamma((df + 1) / 2) / ((gamma(df / 2)) * (df - 1))
ps <- test_DAP_single(gen, func = \(probs) ml_dap_p(probs, mu = mu - 1, alternative = "less"), n_rep = 1000)
hist(ps)
mean(ps < 0.05)
```


ML DAP WIDTS - competitive with https://projecteuclid.org/journals/annals-of-statistics/volume-28/issue-3/Finite-sample-nonparametric-inference-and-large-sample-efficiency/10.1214/aos/1015951997.full (although the two points with n = 10 is a bit worse in our case)

```{r}
ml_dap_ci <- function(probs, B = 10000) {
  m_probs <- mean(probs)
  if(m_probs == 0) {
    lwr <- 0
  } else {
    lwr_func <- \(mu_lwr) SBCBayesFactors:::ml_dap_p(probs, mu_lwr, B = B, alternative = "less") - 0.025
    lwr <- uniroot(lwr_func, c(0, m_probs), tol = 0.001)$root
  }
  
  if(m_probs == 1) {
    upr <- 1
  } else {
    upr_func <- \(mu_upr) SBCBayesFactors:::ml_dap_p(probs, mu_upr, B = B, alternative = "greater") - 0.025
    upr <- uniroot(upr_func, c(m_probs, 1), tol = 0.001)$root
  }
  c(lwr, upr)  
}
```


```{r}
#gen <- \() runif(30)
#true_mean <- 0.5

# Two point
# gen <- \() rbinom(10, prob = 0.05, size = 1)
# true_mean <- 0.05

# Skewed triangle
# gen <- \() rbeta(10, 2, 1)
# true_mean <- 2/3

# Inverted triangle
# n <- 30
# gen <- \() dplyr::if_else(runif(n) < 0.5, 0.5 * rbeta(n, 1, 2), 0.5 + 0.5 * rbeta(n, 2, 1))
# true_mean <- 0.5

# Extra
n <- 30
gen <- \() dplyr::if_else(runif(n) < 0.5, 0.1, 0.5 + 0.5 * rbeta(n, 2, 1))
true_mean <- 0.5 * (0.1 + 0.5 + 1/3)


intervals <- future.apply::future_replicate(1000, {
  probs <- gen()
  
  ml_dap_ci(probs)
})

mean(intervals[1,] <= true_mean & intervals[2,] >= true_mean)
mean(intervals[2,] - intervals[1,])
sd(intervals[2,] - intervals[1,]) / sqrt(ncol(intervals))


```


```{r}
aug_boot_ci <- function(probs, B = 10000) {
  B_lwr <- matrix(sample(c(0, probs), size = B * (length(probs) + 1), replace = TRUE), nrow = B)
  lwr <- quantile(rowMeans(B_lwr), prob = 0.025)
  B_upr <- matrix(sample(c(1, probs), size = B * (length(probs) + 1), replace = TRUE), nrow = B)
  upr <- quantile(rowMeans(B_upr), prob = 0.975)
  as.numeric(c(lwr, upr))
}
```

ML + Gaffke interval is non-trivial even for a single observation, aug_boot is not:

```{r}
ml_dap_ci(0, B = 100000)
gaffke_ci(0, B = 100000)
aug_boot_ci(0, B = 100000)

ml_dap_ci(0.5, B = 100000)
gaffke_ci(0.5, B = 100000)
aug_boot_ci(0.5, B = 100000)

```


```{r}
# gen <- \() runif(10)
# true_mean <- 0.5

#Two-point
# gen <- \() rbinom(2, prob = 0.5, size = 1)
# true_mean <- 0.05

# Skewed triangle
# gen <- \() rbeta(10, 2, 1)
# true_mean <- 2/3

# Inverted triangle
# n <- 30
# gen <- \() dplyr::if_else(runif(n) < 0.5, 0.5 * rbeta(n, 1, 2), 0.5 + 0.5 * rbeta(n, 2, 1))
# true_mean <- 0.5

gen <- \() rbeta(1, 5, 1)
true_mean <- 5/6

intervals <- replicate(1000, {
  probs <- gen()
  aug_boot_ci(probs)
})

mean(intervals[1,] <= true_mean & intervals[2,] >= true_mean)
mean(intervals[2,] - intervals[1,])
sd(intervals[2,] - intervals[1,]) / sqrt(ncol(intervals))


```




```{r}
gaffke_ci <- function(probs, B = 10000, alpha = 0.05) {
  # u_diff <- MCMCpack::rdirichlet(B, alpha = rep(1, length(probs) + 1))
  # u <- apply(u_diff[,1:length(probs)], MARGIN = 1, cumsum)
  # 
  # z_lwr <- diff(c(sort(1 - probs), 1))
  # m_matrix_lwr <- sweep(u, MARGIN = 1, STATS = z_lwr, FUN = "*")
  # m_lwr <- 1 - colSums(m_matrix)
  # 
  # z_upr <- diff(c(sort(probs), 1))
  # m_matrix_upr <- sweep(u, MARGIN = 1, STATS = z_upr, FUN = "*")
  # m_upr <- 1 - colSums(m_matrix)
  # 
  # 1 - quantile(m_lwr, 1 - 0.975)
  # quantile(m_upr, 0.975)
  # as.numeric(quantile(m_upr, c(0.025,0.975)))
  # 
  

  
  
  u_diff <- MCMCpack::rdirichlet(B, alpha = rep(1, length(probs) + 1))

  z_upr <- c(sort(probs), 1)
  m_matrix_upr <- sweep(u_diff, MARGIN = 2, STATS = z_upr, FUN = "*")
  m_upr <- rowSums(m_matrix_upr)

  z_lwr <- c(sort(1 - probs), 1)
  m_matrix_lwr <- sweep(u_diff, MARGIN = 2, STATS = z_lwr, FUN = "*")
  m_lwr <- rowSums(m_matrix_lwr)

  as.numeric(c(
    1 - quantile(m_lwr, probs = 1 - alpha / 2),
    quantile(m_upr, probs = 1 - alpha / 2)
    ))
}


#probs <- rbinom(10, prob = 0.05, size = 1)
probs <- runif(30)
#probs <-  rbeta(27, 2, 1)
#  n <- 30
#  #probs <-  dplyr::if_else(runif(n) < 0.5, 0.5 * rbeta(n, 1, 2), 0.5 + 0.5 * rbeta(n, 2, 1))
# probs <-  dplyr::if_else(runif(n) < 0.5, 0, 0.5 + 0.5 * rbeta(n, 2, 1))


gaffke_ci(probs, B = 100000)
ml_dap_ci(probs, B = 100000)
aug_boot_ci(probs, B = 100000)
t.test(probs)$conf.int
```


## npExact

```{r}
npExact::npMeanSingle(probs, mu = 0.5)$probrej
ml_dap_p(probs, mu = 0.5)
```


```{r}
npExact_ci <- function(probs, alpha = 0.05) {
  if(npExact::npMeanSingle(probs, mu = 1e-6, alpha = alpha)$rejection) {
    low_l <- 0
    low_u <- mean(probs)
    repeat {
      mid <- 0.5 * (low_l + low_u)
      reject_mid <- npExact::npMeanSingle(probs, mu = mid, alpha = alpha)$rejection
      if(reject_mid) {
        low_l <- mid
      } else {
        low_u <- mid
      }
      if(low_u - low_l < 1e-3) {
        low <- low_l
        break
      }
    }
  } else {
    low <- 0
  }
  
  if(npExact::npMeanSingle(probs, mu = 1 - 1e-6, alpha = alpha)$rejection) {
    high_l <- mean(probs)
    high_u <- 1
    repeat {
      mid <- 0.5 * (high_l + high_u)
      reject_mid <- npExact::npMeanSingle(probs, mu = mid, alpha = alpha)$rejection
      if(reject_mid) {
        high_u <- mid
      } else {
        high_l <- mid
      }
      if(high_u - high_l < 1e-3) {
        high <- high_l
        break
      }
    }
  } else {
    high <- 0
  }  
  c(low, high)
}

npExact_ci(probs)
ml_dap_ci(probs)
```


```{r}
microbenchmark::microbenchmark(gaffke_ci(probs), aug_boot_ci(probs), ml_dap_ci(probs), setup = probs <- rbeta(27,2,1))
```


```{r}
# gen <- \() runif(10)
# true_mean <- 0.5

#Two-point
# gen <- \() rbinom(10, prob = 0.05, size = 1)
# true_mean <- 0.05

# Skewed triangle
gen <- \() rbeta(10, 2, 1)
true_mean <- 2/3

# Inverted triangle
# n <- 30
# gen <- \() dplyr::if_else(runif(n) < 0.5, 0.5 * rbeta(n, 1, 2), 0.5 + 0.5 * rbeta(n, 2, 1))
# true_mean <- 0.5


intervals <- future.apply::future_replicate(1000, {
  probs <- gen()
  gaffke_ci(probs, B = 10000)
})

mean(intervals[1,] <= true_mean & intervals[2,] >= true_mean)
mean(intervals[2,] - intervals[1,])
sd(intervals[2,] - intervals[1,]) / sqrt(ncol(intervals))


```


Trying to reconstruct (parts of) Figure 10 from Learned-Miller and Thomas 2019

```{r}
mean_upper_bound_gaffke_ <- function(n, gen, alpha = 0.05) {
  if(n <= 5) {
    cis <- replicate(1000, gaffke_ci(gen(n), B = 10000, alpha = 2*alpha))
  } else {
    if(n < 50) {
      chunk.size <- 500/n
    } else {
      chunk.size <- NULL
    }
    cis <- future.apply::future_replicate(1000, gaffke_ci(gen(n), B = 10000, alpha = 2*alpha), future.chunk.size = chunk.size)
  }
  mean(cis[2,])
}
mean_upper_bound_gaffke <- memoise::memoise(mean_upper_bound_gaffke_)
```


```{r}
n <- c(2, 5, 10, 20, 50, 100, 200, 500, 1000)#unique(round(10^seq(1,3, length.out = 20)))

gen <- \(n) rbeta(n, 1, 10)



ubs <- numeric(length(n))
for(i in seq_along(n)) {
  cat(i, " - ", n[i] , "\n")
  ubs[i] <- mean_upper_bound_gaffke(n[i], gen)
}
```

```{r}
ggplot(data.frame(n = n, ub = ubs), aes(x = n, y = ub)) + geom_hline(yintercept = 1/11) +  geom_line(color = "blue") + scale_x_log10() + scale_y_continuous(breaks = seq(0,1, by = 0.2)) + expand_limits(y = c(0,1))
```

```{r}
data.frame(n = n, ub = ubs)
```


```{r}
func <- hoeffding_p

ps <- test_DAP_single(runif, n = 100000, func = hoeffding_p)
hist(ps)

ps <- test_DAP_single(\() rbinom(n = 100000, size = 1, prob = 0.5) * 0.5 + 0.25, func = hoeffding_p)
hist(ps)

```

```{r}
ps <- numeric(10)
ps[1] <- 1/10
single_samp <- function(){
}
```

