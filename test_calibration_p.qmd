---
title: "test_calibration"
format: html
---

```{r setup}
library(ggplot2)
library(dplyr)
theme_set(theme_minimal())
devtools::load_all()
future::plan(future::multisession)
```


```{r}
test_single <- function(probs_generator, bias = 0, sd = 0, func = calibration_p_saddle, ...) {
  dotlist <- list(...)
  ps <- replicate(100, {
    probs <- do.call(probs_generator, dotlist)
    if(bias != 0 || sd != 0) {
      probs_to_sim <- plogis(
        qlogis(probs) + bias + rnorm(length(probs), mean = 0, sd = sd)
        )
    } else {
      probs_to_sim <- probs
    }
    ys <- rbinom(length(probs), size = 1, prob = probs_to_sim)
    func(probs, ys)
  })
  
  return(ps)
}

func <-  miscalibration_resampling_p
ps <- test_single(runif, func = func, n = 100)
hist(ps)

ps <- test_single(\(n) rbinom(n, size = 1, prob = 0.5), func = func, n = 100)
hist(ps)


ps <- test_single(runif, func = func, n = 10000, bias = 0.5)
hist(ps)

dd <- rbeta(50, 2,1)
hoeffding_p(dd)


probs <- plogis(qlogis(runif(1000)) + 0.5)
hoeffding_p(probs)

ps <- test_single(\(n) rbinom(n, size = 1, prob = 0.4) * 0.3 + 0.2, func = func, n = 1000)
hist(ps)

```


# DAP tests

```{r}
test_DAP_single <- function(probs_generator, bias = 0, sd = 0, func = calibration_p_saddle, n_rep = 100, ...) {
  dotlist <- list(...)
  ps <- replicate(n_rep, {
    probs <- do.call(probs_generator, dotlist)
    if(bias != 0 || sd != 0) {
      probs <- plogis(
        qlogis(probs) + bias + rnorm(length(probs), mean = 0, sd = sd)
        )
    } 
    func(probs)
  })
  
  return(ps)
}


func <- bentkus_p

t_test_p <- function(probs) {
  t <- t.test(probs, mu = 0.5)
  return(t$p.value)
}

ps <- test_DAP_single(rbeta, shape1 = 2, shape2 = 1, n = 20, func = bentkus_p)
#hist(ps)
mean(ps < 0.05)
ps <- test_DAP_single(rbeta, shape1 = 2, shape2 = 1, n = 20, func = hoeffding_p)
#hist(ps)
mean(ps < 0.05)
ps <- test_DAP_single(rbeta, shape1 = 2, shape2 = 1, n = 20, func = t_test_p)
#hist(ps)
mean(ps < 0.05)

ps <- test_DAP_single(runif, n = 10, func = ml_dap_p, n_rep = 1000)
mean(ps < 0.05)
mean(ps < 0.1)
hist(ps)

ps <- test_DAP_single(runif, n = 30, func = ml_dap_p, n_rep = 1000)
mean(ps < 0.05)
mean(ps < 0.1)
hist(ps)

ps <- test_DAP_single(runif, n = 100, func = ml_dap_p)
hist(ps)

ps <- test_DAP_single(runif, n = 1000, func = ml_dap_p)
hist(ps)


ps <- test_DAP_single(\() rbinom(n = 100000, size = 1, prob = 0.5) * 0.5 + 0.25, func = t_test_p)
hist(ps)

ps <- test_DAP_single(\() rbinom(n = 100, size = 1, prob = 0.5) * 0.5 + 0.25, func = ml_dap_p)
hist(ps)


```

```{r}
n <- 1000
#gen <- \() ifelse(runif(n = n) <= 0.5, 0.495, 0.505)
mu_beta <- 0.5
prec_beta <- 40
gen <- \() rbeta(n = n, shape1 = mu_beta * prec_beta, shape2 = (1 - mu_beta)*prec_beta)
ps <- test_DAP_single(gen, func = hoeffding_p)
mean(ps < 0.05)
ps <- test_DAP_single(gen, func = bentkus_p)
mean(ps < 0.05)
ps <- test_DAP_single(gen, func = ml_dap_p)
mean(ps < 0.05)
hist(ps)
# ps <- test_DAP_single(gen, func = t_test_p)
# mean(ps < 0.05)
```


```{r}
n <- 1
gen <- \()  dplyr::if_else(runif(n) < 0.5, 0.1, 0.5 + 0.5 * runif(n))
mu <- 0.5 * (0.1 + 0.75)
ps <- test_DAP_single(gen, func = \(probs) ml_dap_p(probs, mu = mu, alternative = "less"), n_rep = 10000)
mean(ps < 0.99)
hist(ps)

ml_dap_p(0.99, mu = mu, B = 100000, alternative = "less")
mean(ps < 0.5)

hist(ps)

gen2 <- \(n) dplyr::if_else(runif(n) < 0.5, 0.1, 0.5 + 0.5 * runif(n))
zz <- gen2(10000)
hist(dplyr::if_else(zz <= mu, 1, mu / zz))
```
```{r}
mu <- 0.05
gen <- \() rbinom(1, size = 1, prob = mu)
ps <- test_DAP_single(gen, func = \(probs) ml_dap_p(probs, mu = mu, alternative = "less"), n_rep = 1000)
hist(ps)
mean(ps < 0.05)
```

```{r}
df <- 1.5
gen <- \() abs(rt(100, df = df))
# https://distribution-explorer.github.io/continuous/halfstudent_t.html
mu <- 2 * sqrt(df / pi) * gamma((df + 1) / 2) / ((gamma(df / 2)) * (df - 1))
ps <- test_DAP_single(gen, func = \(probs) ml_dap_p(probs, mu = mu - 1, alternative = "less"), n_rep = 1000)
hist(ps)
mean(ps < 0.05)
```


ML DAP WIDTS - competitive with https://projecteuclid.org/journals/annals-of-statistics/volume-28/issue-3/Finite-sample-nonparametric-inference-and-large-sample-efficiency/10.1214/aos/1015951997.full (although the two points with n = 10 is a bit worse in our case)

```{r}
ml_dap_ci <- function(probs, B = 10000) {
  m_probs <- mean(probs)
  if(m_probs == 0) {
    lwr <- 0
  } else {
    lwr_func <- \(mu_lwr) SBCBayesFactors:::ml_dap_p(probs, mu_lwr, B = B, alternative = "less") - 0.025
    lwr <- uniroot(lwr_func, c(0, m_probs), tol = 0.001)$root
  }
  
  if(m_probs == 1) {
    upr <- 1
  } else {
    upr_func <- \(mu_upr) SBCBayesFactors:::ml_dap_p(probs, mu_upr, B = B, alternative = "greater") - 0.025
    upr <- uniroot(upr_func, c(m_probs, 1), tol = 0.001)$root
  }
  c(lwr, upr)  
}
```


```{r}
#gen <- \() runif(30)
#true_mean <- 0.5

# Two point
# gen <- \() rbinom(10, prob = 0.05, size = 1)
# true_mean <- 0.05

# Skewed triangle
# gen <- \() rbeta(10, 2, 1)
# true_mean <- 2/3

# Inverted triangle
# n <- 30
# gen <- \() dplyr::if_else(runif(n) < 0.5, 0.5 * rbeta(n, 1, 2), 0.5 + 0.5 * rbeta(n, 2, 1))
# true_mean <- 0.5

# Extra
n <- 30
gen <- \() dplyr::if_else(runif(n) < 0.5, 0.1, 0.5 + 0.5 * rbeta(n, 2, 1))
true_mean <- 0.5 * (0.1 + 0.5 + 1/3)


intervals <- future.apply::future_replicate(1000, {
  probs <- gen()
  
  ml_dap_ci(probs)
})

mean(intervals[1,] <= true_mean & intervals[2,] >= true_mean)
mean(intervals[2,] - intervals[1,])
sd(intervals[2,] - intervals[1,]) / sqrt(ncol(intervals))


```


```{r}
aug_boot_ci <- function(probs, B = 10000) {
  B_lwr <- matrix(sample(c(0, probs), size = B * (length(probs) + 1), replace = TRUE), nrow = B)
  lwr <- quantile(rowMeans(B_lwr), prob = 0.025)
  B_upr <- matrix(sample(c(1, probs), size = B * (length(probs) + 1), replace = TRUE), nrow = B)
  upr <- quantile(rowMeans(B_upr), prob = 0.975)
  as.numeric(c(lwr, upr))
}
```

ML + Gaffke interval is non-trivial even for a single observation, aug_boot is not:

```{r}
ml_dap_ci(0, B = 100000)
gaffke_ci(0, B = 100000)
aug_boot_ci(0, B = 100000)

ml_dap_ci(0.5, B = 100000)
gaffke_ci(0.5, B = 100000)
aug_boot_ci(0.5, B = 100000)

```


```{r}
# gen <- \() runif(10)
# true_mean <- 0.5

#Two-point
# gen <- \() rbinom(2, prob = 0.5, size = 1)
# true_mean <- 0.05

# Skewed triangle
# gen <- \() rbeta(10, 2, 1)
# true_mean <- 2/3

# Inverted triangle
# n <- 30
# gen <- \() dplyr::if_else(runif(n) < 0.5, 0.5 * rbeta(n, 1, 2), 0.5 + 0.5 * rbeta(n, 2, 1))
# true_mean <- 0.5

gen <- \() rbeta(1, 5, 1)
true_mean <- 5/6

intervals <- replicate(1000, {
  probs <- gen()
  aug_boot_ci(probs)
})

mean(intervals[1,] <= true_mean & intervals[2,] >= true_mean)
mean(intervals[2,] - intervals[1,])
sd(intervals[2,] - intervals[1,]) / sqrt(ncol(intervals))


```




```{r}
gaffke_ci <- function(probs, B = 10000, alpha = 0.05) {
  # u_diff <- MCMCpack::rdirichlet(B, alpha = rep(1, length(probs) + 1))
  # u <- apply(u_diff[,1:length(probs)], MARGIN = 1, cumsum)
  # 
  # z_lwr <- diff(c(sort(1 - probs), 1))
  # m_matrix_lwr <- sweep(u, MARGIN = 1, STATS = z_lwr, FUN = "*")
  # m_lwr <- 1 - colSums(m_matrix)
  # 
  # z_upr <- diff(c(sort(probs), 1))
  # m_matrix_upr <- sweep(u, MARGIN = 1, STATS = z_upr, FUN = "*")
  # m_upr <- 1 - colSums(m_matrix)
  # 
  # 1 - quantile(m_lwr, 1 - 0.975)
  # quantile(m_upr, 0.975)
  # as.numeric(quantile(m_upr, c(0.025,0.975)))
  # 
  

  
  
  u_diff <- MCMCpack::rdirichlet(B, alpha = rep(1, length(probs) + 1))

  z_upr <- c(sort(probs), 1)
  m_matrix_upr <- sweep(u_diff, MARGIN = 2, STATS = z_upr, FUN = "*")
  m_upr <- rowSums(m_matrix_upr)

  z_lwr <- c(sort(1 - probs), 1)
  m_matrix_lwr <- sweep(u_diff, MARGIN = 2, STATS = z_lwr, FUN = "*")
  m_lwr <- rowSums(m_matrix_lwr)

  as.numeric(c(
    1 - quantile(m_lwr, probs = 1 - alpha / 2),
    quantile(m_upr, probs = 1 - alpha / 2)
    ))
}


#probs <- rbinom(10, prob = 0.05, size = 1)
probs <- runif(30)
#probs <-  rbeta(27, 2, 1)
#  n <- 30
#  #probs <-  dplyr::if_else(runif(n) < 0.5, 0.5 * rbeta(n, 1, 2), 0.5 + 0.5 * rbeta(n, 2, 1))
# probs <-  dplyr::if_else(runif(n) < 0.5, 0, 0.5 + 0.5 * rbeta(n, 2, 1))


gaffke_ci(probs, B = 100000)
ml_dap_ci(probs, B = 100000)
aug_boot_ci(probs, B = 100000)
t.test(probs)$conf.int
```


## npExact

```{r}
npExact::npMeanSingle(probs, mu = 0.5)$probrej
ml_dap_p(probs, mu = 0.5)
```


```{r}
npExact_ci <- function(probs, alpha = 0.05) {
  if(npExact::npMeanSingle(probs, mu = 1e-6, alpha = alpha)$rejection) {
    low_l <- 0
    low_u <- mean(probs)
    repeat {
      mid <- 0.5 * (low_l + low_u)
      reject_mid <- npExact::npMeanSingle(probs, mu = mid, alpha = alpha)$rejection
      if(reject_mid) {
        low_l <- mid
      } else {
        low_u <- mid
      }
      if(low_u - low_l < 1e-3) {
        low <- low_l
        break
      }
    }
  } else {
    low <- 0
  }
  
  if(npExact::npMeanSingle(probs, mu = 1 - 1e-6, alpha = alpha)$rejection) {
    high_l <- mean(probs)
    high_u <- 1
    repeat {
      mid <- 0.5 * (high_l + high_u)
      reject_mid <- npExact::npMeanSingle(probs, mu = mid, alpha = alpha)$rejection
      if(reject_mid) {
        high_u <- mid
      } else {
        high_l <- mid
      }
      if(high_u - high_l < 1e-3) {
        high <- high_l
        break
      }
    }
  } else {
    high <- 0
  }  
  c(low, high)
}

npExact_ci(probs)
ml_dap_ci(probs)
```


```{r}
microbenchmark::microbenchmark(gaffke_ci(probs), aug_boot_ci(probs), ml_dap_ci(probs), setup = probs <- rbeta(27,2,1))
```


```{r}
# gen <- \() runif(10)
# true_mean <- 0.5

#Two-point
# gen <- \() rbinom(10, prob = 0.05, size = 1)
# true_mean <- 0.05

# Skewed triangle
gen <- \() rbeta(10, 2, 1)
true_mean <- 2/3

# Inverted triangle
# n <- 30
# gen <- \() dplyr::if_else(runif(n) < 0.5, 0.5 * rbeta(n, 1, 2), 0.5 + 0.5 * rbeta(n, 2, 1))
# true_mean <- 0.5


intervals <- future.apply::future_replicate(1000, {
  probs <- gen()
  gaffke_ci(probs, B = 10000)
})

mean(intervals[1,] <= true_mean & intervals[2,] >= true_mean)
mean(intervals[2,] - intervals[1,])
sd(intervals[2,] - intervals[1,]) / sqrt(ncol(intervals))


```


Trying to reconstruct (parts of) Figure 10 from Learned-Miller and Thomas 2019

```{r}
mean_upper_bound_gaffke_ <- function(n, gen, alpha = 0.05) {
  if(n <= 5) {
    cis <- replicate(1000, gaffke_ci(gen(n), B = 10000, alpha = 2*alpha))
  } else {
    if(n < 50) {
      chunk.size <- 500/n
    } else {
      chunk.size <- NULL
    }
    cis <- future.apply::future_replicate(1000, gaffke_ci(gen(n), B = 10000, alpha = 2*alpha), future.chunk.size = chunk.size)
  }
  mean(cis[2,])
}
mean_upper_bound_gaffke <- memoise::memoise(mean_upper_bound_gaffke_)
```


```{r}
n <- c(2, 5, 10, 20, 50, 100, 200, 500, 1000)#unique(round(10^seq(1,3, length.out = 20)))

gen <- \(n) rbeta(n, 1, 10)



ubs <- numeric(length(n))
for(i in seq_along(n)) {
  cat(i, " - ", n[i] , "\n")
  ubs[i] <- mean_upper_bound_gaffke(n[i], gen)
}
```

```{r}
ggplot(data.frame(n = n, ub = ubs), aes(x = n, y = ub)) + geom_hline(yintercept = 1/11) +  geom_line(color = "blue") + scale_x_log10() + scale_y_continuous(breaks = seq(0,1, by = 0.2)) + expand_limits(y = c(0,1))
```

```{r}
data.frame(n = n, ub = ubs)
```


```{r}
func <- hoeffding_p

ps <- test_DAP_single(runif, n = 100000, func = hoeffding_p)
hist(ps)

ps <- test_DAP_single(\() rbinom(n = 100000, size = 1, prob = 0.5) * 0.5 + 0.25, func = hoeffding_p)
hist(ps)

```

```{r}
ps <- numeric(10)
ps[1] <- 1/10
single_samp <- function(){
}
```

